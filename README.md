# GPT-Model
GPT Model trained on tiny-Shakespeare data
Key Components of the model are:
Word embedding
Positional encoding
multi-headed self-attention (No cross attention)
Transformer Decoder block (No Encoder since it is generating text on its own)
